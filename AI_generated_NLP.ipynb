{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_generated_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dWgxcQQ2BpqXYrFd5bNE_uW684UVyVyn",
      "authorship_tag": "ABX9TyMULcHlVv7zFC4kc5X0PjLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spe301/AI-generated-AI/blob/main/AI_generated_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkPOituvoRXT",
        "outputId": "d8b4ade7-f5ab-4a1a-ad66-8a322a160b68"
      },
      "source": [
        "!pip install Potosnail==0.2.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Potosnail==0.2.3 in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: urllib3==1.25.11 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (1.25.11)\n",
            "Requirement already satisfied: beautifulsoup4==4.9.3 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (4.9.3)\n",
            "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (2.4.1)\n",
            "Requirement already satisfied: lxml==4.6.1 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (4.6.1)\n",
            "Requirement already satisfied: scikit-learn==0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (3.3.4)\n",
            "Requirement already satisfied: xgboost<=1.3.1 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.90)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (1.19.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.11.1)\n",
            "Requirement already satisfied: statsmodels>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.12.2)\n",
            "Requirement already satisfied: regex==2020.10.15 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (2020.10.15)\n",
            "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4==4.9.3->Potosnail==0.2.3) (2.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (2.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2.post1->Potosnail==0.2.3) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2.post1->Potosnail==0.2.3) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.3->Potosnail==0.2.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.3->Potosnail==0.2.3) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.0->Potosnail==0.2.3) (0.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.4.0->Potosnail==0.2.3) (54.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (0.4.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apVtNy1KLP64"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from potosnail import *\r\n",
        "\r\n",
        "ml = MachineLearning()\r\n",
        "dl = DeepLearning()\r\n",
        "dh = DataHelper()\r\n",
        "ev = Evaluater()\r\n",
        "al = Algorithms()\r\n",
        "wr = Wrappers()\r\n",
        "st = Stats()\r\n",
        "\r\n",
        "def SuperBear(df, gridding=False):\r\n",
        "  dh = DataHelper()\r\n",
        "  '''gets the nlp results dataset ready for modeling'''\r\n",
        "  df['regularizer'] = df['regularizer'].fillna('None')\r\n",
        "  df['stacking'] = df['stacking'].astype(int)\r\n",
        "  df['dropout'] = df['dropout'].astype(int)\r\n",
        "  df['bidirectional'] = df['bidirectional'].astype(int)\r\n",
        "  act = dh.OHE(df['activation'])\r\n",
        "  reg = dh.OHE(df['regularizer'])\r\n",
        "  opt = dh.OHE(df['optimizer'])\r\n",
        "  method = dh.OHE(df['method'])\r\n",
        "  df = df.drop(['activation', 'regularizer', 'optimizer', 'method'], axis='columns')\r\n",
        "  df = pd.concat([df, act, reg, opt, method], axis='columns')\r\n",
        "  if gridding == True:\r\n",
        "    return df\r\n",
        "  df['val_loss'] = df['val_loss'].fillna(max(df['val_loss']))\r\n",
        "  df['loss'] = df['loss'].fillna(max(df['loss']))\r\n",
        "  kpi_list = ['accuracy', 'loss', 'val_accuracy', 'val_loss']\r\n",
        "  kpi = df[kpi_list]\r\n",
        "  scores = []\r\n",
        "  for i in range(len(df)):\r\n",
        "    ts = (1 - (kpi['loss'][i] / max(kpi['loss'])) + kpi['accuracy'][i])/2\r\n",
        "    vs = (1 - (kpi['val_loss'][i] / max(kpi['val_loss'])) + kpi['val_accuracy'][i])/2\r\n",
        "    score = (ts+vs) - abs(ts-vs)\r\n",
        "    scores.append(score)\r\n",
        "  df2 = df.drop(kpi_list, axis='columns')\r\n",
        "  df2['quality'] = scores\r\n",
        "  return df2\r\n",
        "\r\n",
        "def BunnyPinkears(params, len_dataset, n_features, dominant_class):\r\n",
        "  '''puts all possible gridsearch combinations in a dataframe'''\r\n",
        "  n = list(params.keys())\r\n",
        "  lst1 = []\r\n",
        "  lst2 = []\r\n",
        "  lst3 = []\r\n",
        "  lst4 = []\r\n",
        "  lst5 = []\r\n",
        "  lst6 = []\r\n",
        "  lst7 = []\r\n",
        "  lst8 = []\r\n",
        "  lst9 = []\r\n",
        "  lst10 = []\r\n",
        "  lst11 = []\r\n",
        "  lst12 = []\r\n",
        "  for i in range(len(params[n[0]])):\r\n",
        "    var1 = params[n[0]][i]\r\n",
        "    for i in range(len(params[n[1]])):\r\n",
        "      var2 = params[n[1]][i]\r\n",
        "      for i in range(len(params[n[2]])):\r\n",
        "        var3 = params[n[2]][i]\r\n",
        "        for i in range(len(params[n[3]])):\r\n",
        "          var4 = params[n[3]][i]\r\n",
        "          for i in range(len(params[n[4]])):\r\n",
        "            var5 = params[n[4]][i]\r\n",
        "            for i in range(len(params[n[5]])):\r\n",
        "              var6 = params[n[5]][i]\r\n",
        "              for i in range(len(params[n[6]])):\r\n",
        "                var7 = params[n[6]][i]\r\n",
        "                for i in range(len(params[n[7]])):\r\n",
        "                  var8 = params[n[7]][i]\r\n",
        "                  for i in range(len(params[n[8]])):\r\n",
        "                    var9 = params[n[8]][i]\r\n",
        "                    for i in range(len(params[n[9]])):\r\n",
        "                      var10 = params[n[9]][i]\r\n",
        "                      for i in range(len(params[n[10]])):\r\n",
        "                        var11 = params[n[10]][i]\r\n",
        "                        for i in range(len(params[n[11]])):\r\n",
        "                          var12 = params[n[11]][i]\r\n",
        "                          lst1.append(var1)\r\n",
        "                          lst2.append(var2)\r\n",
        "                          lst3.append(var3)\r\n",
        "                          lst4.append(var4)\r\n",
        "                          lst5.append(var5)\r\n",
        "                          lst6.append(var6)\r\n",
        "                          lst7.append(var7)\r\n",
        "                          lst8.append(var8)\r\n",
        "                          lst9.append(var9)\r\n",
        "                          lst10.append(var10)\r\n",
        "                          lst11.append(var11)\r\n",
        "                          lst12.append(var12)\r\n",
        "  df = pd.DataFrame(lst1)\r\n",
        "  df.columns = [n[0]]\r\n",
        "  df[n[1]] = lst2\r\n",
        "  df[n[2]] = lst3\r\n",
        "  df[n[3]] = lst4\r\n",
        "  df[n[4]] = lst5\r\n",
        "  df[n[5]] = lst6\r\n",
        "  df[n[6]] = lst7\r\n",
        "  df[n[7]] = lst8\r\n",
        "  df[n[8]] = lst9\r\n",
        "  df[n[9]] = lst10\r\n",
        "  df[n[10]] = lst11\r\n",
        "  df[n[11]] = lst12\r\n",
        "  df['len_dataset'] = [len_dataset] * len(df)\r\n",
        "  df['n_features'] = [n_features] * len(df)\r\n",
        "  df['dominant_class'] = [dominant_class] * len(df)\r\n",
        "  return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "298ew3nYB7sw"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/spe301/AI-generated-AI/main/Data/NLP8.csv').drop(['Unnamed: 0'], axis='columns')\r\n",
        "#train, val = dh.HoldOut(df)\r\n",
        "\r\n",
        "grid = {'output_dim': [2], #because we have 2 classes\r\n",
        "          'embedding': [45589], #vocab is number of unique words in dataset\r\n",
        "          'nodes': list(range(32, 68, 4)), #we will test between 32 and 64 nodes for the first layer\r\n",
        "          'activation': ['tanh', 'relu'], #we will test between relu and tanh for activation function\r\n",
        "          'regularizer': ['L1', None, 'L2'], #we will use L1 reqularization to prevent overfitting\r\n",
        "          'stacking': [False, True], #stacking makes the first 2 layers the same, we will not do this\r\n",
        "          'dropout': [False, True], #we will not use dropout because we are already using L1 regularization\r\n",
        "          'optimizer': ['adam', 'rmsprop', 'sgd'], #we will test between adam and rmsprop for optimization function\r\n",
        "          'method': ['LSTM', 'GRU'], #we will test between using an LSTM cell and a GRU cell\r\n",
        "          'bidirectional': [True, False], 'epochs': list(range(5, 60, 5)), 'batch_size': [32, 64]}\r\n",
        "\r\n",
        "def ModelBuilder(df, task):\r\n",
        "  if task == 'NLP':\r\n",
        "    df2 = SuperBear(df)\r\n",
        "  vanilla, grid, X, Xval, y, yval = wr.Vanilla(df2, 'quality', 'regression')\r\n",
        "  scaler = al.PickScaler(X, y, vanilla)\r\n",
        "  Xs = dh.ScaleData(scaler, X)\r\n",
        "  model = ml.Optimize(vanilla, grid, Xs, y)\r\n",
        "  return model, scaler\r\n",
        "\r\n",
        "def PredictCombos(df, grid, task, len_dataset=0, n_features=0, dominant_class=0.5): #X, y, Xval, yval\r\n",
        "  model, scaler = ModelBuilder(df, task)\r\n",
        "  combinations = SuperBear(BunnyPinkears(grid, len_dataset, n_features, dominant_class), gridding=True)\r\n",
        "  if len(kit) == 5:\r\n",
        "    cols = list(kit[1].drop(['quality'], axis='columns').columns)\r\n",
        "  if len(kit) == 7:\r\n",
        "    cols = list(kit[1].columns)\r\n",
        "  try:\r\n",
        "    c2 = combinations[cols]\r\n",
        "  except:\r\n",
        "    c2 = dh.ScaleData(kit[:-2], combinations)[cols]\r\n",
        "  c2['quality'] = model.predict(c2)\r\n",
        "  return kit"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1FsOTjsO_1K",
        "outputId": "3ea5da86-115e-49aa-c947-c84de79b8444"
      },
      "source": [
        "ModelBuilder(df, 'NLP')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=8,\n",
              "                       max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best'), 'standard')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "oxhtL12s47JR",
        "outputId": "e65528bb-3e4d-41c0-d163-65255492eef8"
      },
      "source": [
        "PredictCombos(df, grid, 'NLP', len_dataset=360, n_features=1724)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    1.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a5108c2c0cff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPredictCombos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NLP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1724\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-5dbf58da1054>\u001b[0m in \u001b[0;36mPredictCombos\u001b[0;34m(df, grid, task, len_dataset, n_features, dominant_class)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScaleData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mkit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 5 and input n_features is 21 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "9esC9_8MMGpi",
        "outputId": "c82fea05-93ed-4ee7-88dc-7b2957361237"
      },
      "source": [
        "kit = wr.RegLoop(SuperBear(df), 'quality', quiet=False)\r\n",
        "list(kit.values())[0][0].predict(list(kit.values())[0][3])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.5% accuracy, untuned model, raw data\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80.94% accuracy, tuned model, raw data\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "74.33% accuracy, tuned model, data is scaled with standard scaler\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13.51% accuracy, tuned model, features have been reduced to 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    1.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-c52284d70465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSuperBear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 5 and input n_features is 21 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9wO1pmspmrW"
      },
      "source": [
        "train, val = dh.HoldOut(nlp2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nussxRqSpy8U",
        "outputId": "ff498612-8126-4c23-d583-ca679367ce4c"
      },
      "source": [
        "kit = wr.WrapML(train, 'quality', 'regression', quiet=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72.56% accuracy, untuned model, raw data\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "71.43% accuracy, tuned model, raw data\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80.98% accuracy, tuned model, data is scaled with standard scaler\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20.56% accuracy, tuned model, features have been reduced to 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    1.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giZ2Wocj1LLs"
      },
      "source": [
        "model = list(kit.values())[0][0]\r\n",
        "X = list(kit.values())[0][1]\r\n",
        "y = list(kit.values())[0][2]\r\n",
        "Xval = val.drop(['quality'], axis='columns')\r\n",
        "yval = val['quality']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjlE5wXx1M9P",
        "outputId": "f5bb1467-c7ad-4094-e91b-beb949d07ba4"
      },
      "source": [
        "model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q9C3qQqk2CA9",
        "outputId": "9c146f85-d320-4a8a-d51d-61fdebc0616f"
      },
      "source": [
        "'''grid = {'max_depth': [11, 12, 13], 'max_leaf_nodes': [9, 12, 15], 'min_samples_leaf': [3, 4]}\r\n",
        "\r\n",
        "clf = ml.Optimize(model, grid, X, y)\r\n",
        "clf'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"grid = {'max_depth': [11, 12, 13], 'max_leaf_nodes': [9, 12, 15], 'min_samples_leaf': [3, 4]}\\n\\nclf = ml.Optimize(model, grid, X, y)\\nclf\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itXCCOyP2RIl",
        "outputId": "b42b0184-e3f8-4753-9f45-d834c18873f0"
      },
      "source": [
        "ev.EvaluateRegressor(model, X, Xval, y, yval)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(     predicted    actual     error    %error\n",
              " 0     1.154930  1.136725  0.018204  0.984238\n",
              " 1     1.142370  1.128174  0.014196  0.987573\n",
              " 2     1.104107  1.133143  0.029035  2.562384\n",
              " 3     1.123472  1.138898  0.015426  1.354444\n",
              " 4     1.427865  1.426996  0.000869  0.999391\n",
              " ..         ...       ...       ...       ...\n",
              " 195   0.500000  0.500000  0.000000  0.000000\n",
              " 196   1.457593  1.487217  0.029624  1.991884\n",
              " 197   1.388665  1.365349  0.023316  0.983210\n",
              " 198   0.500000  0.500000  0.000000  0.000000\n",
              " 199   1.165965  1.081516  0.084449  0.927571\n",
              " \n",
              " [200 rows x 4 columns], 0.012085341723610971, 70.56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7mbd3qa44gz"
      },
      "source": [
        "X = np.array(X)\r\n",
        "Xval = np.array(Xval)\r\n",
        "y = np.array(y)\r\n",
        "yval = np.array(yval)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzF--3Yx5Knd",
        "outputId": "56425786-1ab7-4e2a-92eb-32cadc5206c3"
      },
      "source": [
        "dm = dl.FastNN('regression', 'mse', output_dim=1)\r\n",
        "history = dm.fit(X, y, epochs=150, batch_size=32, validation_split=0.2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "41/41 [==============================] - 1s 12ms/step - loss: 433090.1187 - val_loss: 4694.1646\n",
            "Epoch 2/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 2372.1694 - val_loss: 103.0036\n",
            "Epoch 3/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 41.3307 - val_loss: 0.7357\n",
            "Epoch 4/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 1.1027 - val_loss: 0.5430\n",
            "Epoch 5/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5857 - val_loss: 0.5167\n",
            "Epoch 6/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.6438 - val_loss: 0.5198\n",
            "Epoch 7/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.4878\n",
            "Epoch 8/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5508 - val_loss: 0.4947\n",
            "Epoch 9/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5500 - val_loss: 0.4770\n",
            "Epoch 10/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5452 - val_loss: 0.4665\n",
            "Epoch 11/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5404 - val_loss: 0.5706\n",
            "Epoch 12/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5881 - val_loss: 0.4735\n",
            "Epoch 13/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5065 - val_loss: 0.4777\n",
            "Epoch 14/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 0.4532\n",
            "Epoch 15/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5717 - val_loss: 0.5898\n",
            "Epoch 16/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 0.5825\n",
            "Epoch 17/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5829 - val_loss: 0.4810\n",
            "Epoch 18/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.5145\n",
            "Epoch 19/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.6497 - val_loss: 0.5035\n",
            "Epoch 20/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5554 - val_loss: 0.4902\n",
            "Epoch 21/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5806 - val_loss: 0.5511\n",
            "Epoch 22/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5049 - val_loss: 0.4834\n",
            "Epoch 23/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.5003\n",
            "Epoch 24/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5515 - val_loss: 0.4208\n",
            "Epoch 25/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5155 - val_loss: 0.6588\n",
            "Epoch 26/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.5542\n",
            "Epoch 27/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 0.4575\n",
            "Epoch 28/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.4811\n",
            "Epoch 29/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5526 - val_loss: 0.4127\n",
            "Epoch 30/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 0.4080\n",
            "Epoch 31/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.4220\n",
            "Epoch 32/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4682 - val_loss: 0.4873\n",
            "Epoch 33/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5350 - val_loss: 0.3964\n",
            "Epoch 34/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.4023\n",
            "Epoch 35/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.3992\n",
            "Epoch 36/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.3924\n",
            "Epoch 37/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4756\n",
            "Epoch 38/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.4540\n",
            "Epoch 39/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.3471\n",
            "Epoch 40/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5442 - val_loss: 0.3268\n",
            "Epoch 41/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4285 - val_loss: 0.3203\n",
            "Epoch 42/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4027 - val_loss: 0.7031\n",
            "Epoch 43/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5671 - val_loss: 0.4244\n",
            "Epoch 44/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5283 - val_loss: 0.4243\n",
            "Epoch 45/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.2950\n",
            "Epoch 46/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.7667\n",
            "Epoch 47/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5371 - val_loss: 0.3752\n",
            "Epoch 48/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.3073\n",
            "Epoch 49/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.2812\n",
            "Epoch 50/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3911\n",
            "Epoch 51/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.3242\n",
            "Epoch 52/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4905 - val_loss: 0.2829\n",
            "Epoch 53/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3984 - val_loss: 0.2901\n",
            "Epoch 54/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4377 - val_loss: 0.2618\n",
            "Epoch 55/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3494 - val_loss: 0.3472\n",
            "Epoch 56/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4113 - val_loss: 0.2521\n",
            "Epoch 57/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3971 - val_loss: 0.2469\n",
            "Epoch 58/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.4628\n",
            "Epoch 59/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.2433\n",
            "Epoch 60/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.2761\n",
            "Epoch 61/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3591 - val_loss: 0.4327\n",
            "Epoch 62/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4288 - val_loss: 0.7038\n",
            "Epoch 63/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4972 - val_loss: 0.2273\n",
            "Epoch 64/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4935 - val_loss: 0.8939\n",
            "Epoch 65/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4206 - val_loss: 0.2394\n",
            "Epoch 66/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.2817\n",
            "Epoch 67/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.5395\n",
            "Epoch 68/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4224 - val_loss: 0.3390\n",
            "Epoch 69/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4049 - val_loss: 0.2690\n",
            "Epoch 70/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3061 - val_loss: 0.4826\n",
            "Epoch 71/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5225 - val_loss: 0.5195\n",
            "Epoch 72/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4126\n",
            "Epoch 73/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3878 - val_loss: 0.2648\n",
            "Epoch 74/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.2959 - val_loss: 0.2114\n",
            "Epoch 75/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3083 - val_loss: 0.6971\n",
            "Epoch 76/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.2679\n",
            "Epoch 77/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4269 - val_loss: 0.9340\n",
            "Epoch 78/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5804 - val_loss: 0.2274\n",
            "Epoch 79/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.1720\n",
            "Epoch 80/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.2953 - val_loss: 0.3431\n",
            "Epoch 81/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.2357 - val_loss: 0.5548\n",
            "Epoch 82/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3655 - val_loss: 0.3656\n",
            "Epoch 83/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3769 - val_loss: 0.1993\n",
            "Epoch 84/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3966 - val_loss: 0.5680\n",
            "Epoch 85/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7268 - val_loss: 2.2325\n",
            "Epoch 86/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 1.0859 - val_loss: 0.3372\n",
            "Epoch 87/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.2728\n",
            "Epoch 88/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3366 - val_loss: 0.1737\n",
            "Epoch 89/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.2457 - val_loss: 0.3166\n",
            "Epoch 90/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.3109 - val_loss: 0.3491\n",
            "Epoch 91/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5775 - val_loss: 0.6642\n",
            "Epoch 92/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.6837 - val_loss: 0.4517\n",
            "Epoch 93/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5257 - val_loss: 0.3654\n",
            "Epoch 94/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4526 - val_loss: 0.2305\n",
            "Epoch 95/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.7531\n",
            "Epoch 96/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 1.3282 - val_loss: 0.3276\n",
            "Epoch 97/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.5741 - val_loss: 0.9385\n",
            "Epoch 98/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.9104 - val_loss: 0.1664\n",
            "Epoch 99/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.1994 - val_loss: 0.1681\n",
            "Epoch 100/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3384 - val_loss: 0.4112\n",
            "Epoch 101/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.7362 - val_loss: 0.3596\n",
            "Epoch 102/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.6715 - val_loss: 1.2068\n",
            "Epoch 103/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 6.7131 - val_loss: 6.0171\n",
            "Epoch 104/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 16.4067 - val_loss: 9.4071\n",
            "Epoch 105/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 7.2906 - val_loss: 0.4251\n",
            "Epoch 106/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.8534 - val_loss: 0.2273\n",
            "Epoch 107/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.4909 - val_loss: 0.2543\n",
            "Epoch 108/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.4494\n",
            "Epoch 109/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.8166 - val_loss: 1.1289\n",
            "Epoch 110/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 9.2983 - val_loss: 1.5222\n",
            "Epoch 111/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 20.9188 - val_loss: 133.9810\n",
            "Epoch 112/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 76.4170 - val_loss: 44.9605\n",
            "Epoch 113/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 39.1676 - val_loss: 220.8597\n",
            "Epoch 114/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 137.1297 - val_loss: 5.6216\n",
            "Epoch 115/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 36.6160 - val_loss: 44.6199\n",
            "Epoch 116/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 209.7143 - val_loss: 2269.9851\n",
            "Epoch 117/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 800.9226 - val_loss: 909.1054\n",
            "Epoch 118/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 343.5573 - val_loss: 345.3322\n",
            "Epoch 119/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 159.8596 - val_loss: 23.5551\n",
            "Epoch 120/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 28.9327 - val_loss: 1.9172\n",
            "Epoch 121/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 2.5687 - val_loss: 0.2393\n",
            "Epoch 122/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.2891 - val_loss: 0.3778\n",
            "Epoch 123/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.2692 - val_loss: 0.1299\n",
            "Epoch 124/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.2070\n",
            "Epoch 125/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.2249 - val_loss: 0.2333\n",
            "Epoch 126/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.5228\n",
            "Epoch 127/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4954 - val_loss: 0.6893\n",
            "Epoch 128/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.7861 - val_loss: 0.1054\n",
            "Epoch 129/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.7543\n",
            "Epoch 130/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.4842\n",
            "Epoch 131/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 5.1803 - val_loss: 12.7455\n",
            "Epoch 132/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 9.8353 - val_loss: 0.6413\n",
            "Epoch 133/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 23.1911 - val_loss: 243.4084\n",
            "Epoch 134/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 159.8947 - val_loss: 15.7302\n",
            "Epoch 135/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 19.7930 - val_loss: 1.6883\n",
            "Epoch 136/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 29.1837 - val_loss: 0.2074\n",
            "Epoch 137/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 24.6709 - val_loss: 49.5102\n",
            "Epoch 138/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 108.6668 - val_loss: 43.2736\n",
            "Epoch 139/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 38.1916 - val_loss: 215.1868\n",
            "Epoch 140/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 129.2477 - val_loss: 3.8618\n",
            "Epoch 141/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 5.1464 - val_loss: 0.0861\n",
            "Epoch 142/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 3.7171 - val_loss: 134.9445\n",
            "Epoch 143/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 62.3623 - val_loss: 8.0787\n",
            "Epoch 144/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 12.0053 - val_loss: 112.3846\n",
            "Epoch 145/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 255.1145 - val_loss: 342.4806\n",
            "Epoch 146/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 219.2011 - val_loss: 208.6384\n",
            "Epoch 147/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 325.7872 - val_loss: 19.7646\n",
            "Epoch 148/150\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 44.3972 - val_loss: 5.6176\n",
            "Epoch 149/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 9.6902 - val_loss: 32.9635\n",
            "Epoch 150/150\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 15.1678 - val_loss: 0.4990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pkE1KbW55Nj",
        "outputId": "2f51a1bc-3d27-437e-b90a-29a33348f952"
      },
      "source": [
        "dm.evaluate(Xval, yval)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 1ms/step - loss: 0.4871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4870617985725403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "hmZf6qwR6Fsa",
        "outputId": "2b0b476b-d0a9-4ffd-e1f1-29b1ade69c93"
      },
      "source": [
        "ev.ViewLoss(history)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "nx5SkL8PB-WR",
        "outputId": "9e21cb87-93d9-4761-8867-b00976532136"
      },
      "source": [
        "def BunnyPinkears(params, len_dataset, n_features, dominant_class):\r\n",
        "  '''puts all possible gridsearch combinations in a dataframe'''\r\n",
        "  n = list(params.keys())\r\n",
        "  lst1 = []\r\n",
        "  lst2 = []\r\n",
        "  lst3 = []\r\n",
        "  lst4 = []\r\n",
        "  lst5 = []\r\n",
        "  lst6 = []\r\n",
        "  lst7 = []\r\n",
        "  lst8 = []\r\n",
        "  lst9 = []\r\n",
        "  lst10 = []\r\n",
        "  lst11 = []\r\n",
        "  lst12 = []\r\n",
        "  for i in range(len(params[n[0]])):\r\n",
        "    var1 = params[n[0]][i]\r\n",
        "    for i in range(len(params[n[1]])):\r\n",
        "      var2 = params[n[1]][i]\r\n",
        "      for i in range(len(params[n[2]])):\r\n",
        "        var3 = params[n[2]][i]\r\n",
        "        for i in range(len(params[n[3]])):\r\n",
        "          var4 = params[n[3]][i]\r\n",
        "          for i in range(len(params[n[4]])):\r\n",
        "            var5 = params[n[4]][i]\r\n",
        "            for i in range(len(params[n[5]])):\r\n",
        "              var6 = params[n[5]][i]\r\n",
        "              for i in range(len(params[n[6]])):\r\n",
        "                var7 = params[n[6]][i]\r\n",
        "                for i in range(len(params[n[7]])):\r\n",
        "                  var8 = params[n[7]][i]\r\n",
        "                  for i in range(len(params[n[8]])):\r\n",
        "                    var9 = params[n[8]][i]\r\n",
        "                    for i in range(len(params[n[9]])):\r\n",
        "                      var10 = params[n[9]][i]\r\n",
        "                      for i in range(len(params[n[10]])):\r\n",
        "                        var11 = params[n[10]][i]\r\n",
        "                        for i in range(len(params[n[11]])):\r\n",
        "                          var12 = params[n[11]][i]\r\n",
        "                          lst1.append(var1)\r\n",
        "                          lst2.append(var2)\r\n",
        "                          lst3.append(var3)\r\n",
        "                          lst4.append(var4)\r\n",
        "                          lst5.append(var5)\r\n",
        "                          lst6.append(var6)\r\n",
        "                          lst7.append(var7)\r\n",
        "                          lst8.append(var8)\r\n",
        "                          lst9.append(var9)\r\n",
        "                          lst10.append(var10)\r\n",
        "                          lst11.append(var11)\r\n",
        "                          lst12.append(var12)\r\n",
        "  df = pd.DataFrame(lst1)\r\n",
        "  df.columns = [n[0]]\r\n",
        "  df[n[1]] = lst2\r\n",
        "  df[n[2]] = lst3\r\n",
        "  df[n[3]] = lst4\r\n",
        "  df[n[4]] = lst5\r\n",
        "  df[n[5]] = lst6\r\n",
        "  df[n[6]] = lst7\r\n",
        "  df[n[7]] = lst8\r\n",
        "  df[n[8]] = lst9\r\n",
        "  df[n[9]] = lst10\r\n",
        "  df[n[10]] = lst11\r\n",
        "  df[n[11]] = lst12\r\n",
        "  df['len_dataset'] = [len_dataset] * len(df)\r\n",
        "  df['n_features'] = [n_features] * len(df)\r\n",
        "  df['dominant_class'] = [dominant_class] * len(df)\r\n",
        "  return df\r\n",
        "                    \r\n",
        "                    \r\n",
        "grid = {'output_dim': [2], #because we have 2 classes\r\n",
        "          'embedding': [45589], #vocab is number of unique words in dataset\r\n",
        "          'nodes': list(range(32, 68, 4)), #we will test between 32 and 64 nodes for the first layer\r\n",
        "          'activation': ['tanh', 'relu'], #we will test between relu and tanh for activation function\r\n",
        "          'regularizer': ['L1', None, 'L2'], #we will use L1 reqularization to prevent overfitting\r\n",
        "          'stacking': [False, True], #stacking makes the first 2 layers the same, we will not do this\r\n",
        "          'dropout': [False, True], #we will not use dropout because we are already using L1 regularization\r\n",
        "          'optimizer': ['adam', 'rmsprop', 'sgd'], #we will test between adam and rmsprop for optimization function\r\n",
        "          'method': ['LSTM', 'GRU'], #we will test between using an LSTM cell and a GRU cell\r\n",
        "          'bidirectional': [True, False], 'epochs': list(range(5, 60, 5)), 'batch_size': [32, 64]}\r\n",
        "\r\n",
        "InpGrid = BunnyPinkears(grid, 360, 17, 0.5)    \r\n",
        "NlpGrid = SuperBear(InpGrid, gridding=True)\r\n",
        "NlpGrid"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>output_dim</th>\n",
              "      <th>embedding</th>\n",
              "      <th>nodes</th>\n",
              "      <th>stacking</th>\n",
              "      <th>dropout</th>\n",
              "      <th>bidirectional</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>len_dataset</th>\n",
              "      <th>n_features</th>\n",
              "      <th>dominant_class</th>\n",
              "      <th>relu</th>\n",
              "      <th>tanh</th>\n",
              "      <th>L1</th>\n",
              "      <th>L2</th>\n",
              "      <th>None</th>\n",
              "      <th>adam</th>\n",
              "      <th>rmsprop</th>\n",
              "      <th>sgd</th>\n",
              "      <th>GRU</th>\n",
              "      <th>LSTM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57019</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57020</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57021</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57022</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57023</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57024 rows  21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       output_dim  embedding  nodes  stacking  ...  rmsprop  sgd  GRU  LSTM\n",
              "0               2      45589     32         0  ...      0.0  0.0  0.0   1.0\n",
              "1               2      45589     32         0  ...      0.0  0.0  0.0   1.0\n",
              "2               2      45589     32         0  ...      0.0  0.0  0.0   1.0\n",
              "3               2      45589     32         0  ...      0.0  0.0  0.0   1.0\n",
              "4               2      45589     32         0  ...      0.0  0.0  0.0   1.0\n",
              "...           ...        ...    ...       ...  ...      ...  ...  ...   ...\n",
              "57019           2      45589     64         1  ...      0.0  1.0  1.0   0.0\n",
              "57020           2      45589     64         1  ...      0.0  1.0  1.0   0.0\n",
              "57021           2      45589     64         1  ...      0.0  1.0  1.0   0.0\n",
              "57022           2      45589     64         1  ...      0.0  1.0  1.0   0.0\n",
              "57023           2      45589     64         1  ...      0.0  1.0  1.0   0.0\n",
              "\n",
              "[57024 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "YqedqOEpBZSB",
        "outputId": "1a7778de-41e7-4893-b2c8-6aef3f22e03c"
      },
      "source": [
        "NlpGrid['quality'] = model.predict(NlpGrid)\r\n",
        "NlpGrid"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>output_dim</th>\n",
              "      <th>embedding</th>\n",
              "      <th>nodes</th>\n",
              "      <th>stacking</th>\n",
              "      <th>dropout</th>\n",
              "      <th>bidirectional</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>len_dataset</th>\n",
              "      <th>n_features</th>\n",
              "      <th>dominant_class</th>\n",
              "      <th>relu</th>\n",
              "      <th>tanh</th>\n",
              "      <th>L1</th>\n",
              "      <th>L2</th>\n",
              "      <th>None</th>\n",
              "      <th>adam</th>\n",
              "      <th>rmsprop</th>\n",
              "      <th>sgd</th>\n",
              "      <th>GRU</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.387853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.387853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.185807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.185807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.185807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57019</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.158815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57020</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.158815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57021</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.158815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57022</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>32</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.158815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57023</th>\n",
              "      <td>2</td>\n",
              "      <td>45589</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>64</td>\n",
              "      <td>360</td>\n",
              "      <td>17</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.158815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57024 rows  22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       output_dim  embedding  nodes  stacking  ...  sgd  GRU  LSTM   quality\n",
              "0               2      45589     32         0  ...  0.0  0.0   1.0  1.387853\n",
              "1               2      45589     32         0  ...  0.0  0.0   1.0  1.387853\n",
              "2               2      45589     32         0  ...  0.0  0.0   1.0  1.185807\n",
              "3               2      45589     32         0  ...  0.0  0.0   1.0  1.185807\n",
              "4               2      45589     32         0  ...  0.0  0.0   1.0  1.185807\n",
              "...           ...        ...    ...       ...  ...  ...  ...   ...       ...\n",
              "57019           2      45589     64         1  ...  1.0  1.0   0.0  1.158815\n",
              "57020           2      45589     64         1  ...  1.0  1.0   0.0  1.158815\n",
              "57021           2      45589     64         1  ...  1.0  1.0   0.0  1.158815\n",
              "57022           2      45589     64         1  ...  1.0  1.0   0.0  1.158815\n",
              "57023           2      45589     64         1  ...  1.0  1.0   0.0  1.158815\n",
              "\n",
              "[57024 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPwUy0qiGFVp"
      },
      "source": [
        "res = dict(NlpGrid.loc[NlpGrid['quality'] == max(NlpGrid['quality'])].iloc[0])\r\n",
        "\r\n",
        "if res['relu'] == 1:\r\n",
        "  activation = 'relu'\r\n",
        "if res['tanh'] == 1:\r\n",
        "  activation = 'tanh'\r\n",
        "if res['L1'] == 1:\r\n",
        "  regularizer = 'L1' \r\n",
        "if res['L2'] == 1:\r\n",
        "  regularizer = 'L2' \r\n",
        "if res['None'] == 1:\r\n",
        "  regularizer = 'None' \r\n",
        "if res['adam'] == 1:\r\n",
        "  optimizer = 'adam'\r\n",
        "if res['rmsprop'] == 1:\r\n",
        "  optimizer = 'rmsprop'\r\n",
        "if res['sgd'] == 1:\r\n",
        "  optimizer = 'sgd'\r\n",
        "if res['GRU'] == 1:\r\n",
        "  method = 'GRU'\r\n",
        "if res['LSTM'] == 1:\r\n",
        "  method = 'LSTM' "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIBSFmEtQPQ_",
        "outputId": "10ed8e9e-3bec-4b15-f754-1cbbbbdf795e"
      },
      "source": [
        "dm3 = dl.RNN(int(res['output_dim']), int(res['embedding']), int(res['nodes']), activation, regularizer, bool(res['stacking']), bool(res['dropout']), optimizer, method, bool(res['bidirectional']))\r\n",
        "dm3.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          1458848   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 64)          16640     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 32)          10368     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, None, 16)          528       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, None, 2)           34        \n",
            "=================================================================\n",
            "Total params: 1,486,418\n",
            "Trainable params: 1,486,418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}