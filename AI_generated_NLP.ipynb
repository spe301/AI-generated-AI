{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_generated_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dWgxcQQ2BpqXYrFd5bNE_uW684UVyVyn",
      "authorship_tag": "ABX9TyMAjGi8HLWO6sISZeD/6xRf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spe301/AI-generated-AI/blob/main/AI_generated_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkPOituvoRXT",
        "outputId": "acdff285-40bb-4115-c644-5d6777406d3a"
      },
      "source": [
        "!pip install Potosnail==0.2.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Potosnail==0.2.3 in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: xgboost<=1.3.1 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.90)\n",
            "Requirement already satisfied: lxml==4.6.1 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (4.6.1)\n",
            "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (2.4.1)\n",
            "Requirement already satisfied: beautifulsoup4==4.9.3 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (4.9.3)\n",
            "Requirement already satisfied: regex==2020.10.15 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (2020.10.15)\n",
            "Requirement already satisfied: pandas>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (1.1.5)\n",
            "Requirement already satisfied: urllib3==1.25.11 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (1.25.11)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn==0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (3.3.4)\n",
            "Requirement already satisfied: statsmodels>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.12.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from Potosnail==0.2.3) (0.11.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost<=1.3.1->Potosnail==0.2.3) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (2.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->Potosnail==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4==4.9.3->Potosnail==0.2.3) (2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.3->Potosnail==0.2.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.3->Potosnail==0.2.3) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2.post1->Potosnail==0.2.3) (1.0.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.2->Potosnail==0.2.3) (1.3.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.0->Potosnail==0.2.3) (0.5.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (0.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (54.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.27.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->Potosnail==0.2.3) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apVtNy1KLP64"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from potosnail import *\r\n",
        "\r\n",
        "ml = MachineLearning()\r\n",
        "dl = DeepLearning()\r\n",
        "dh = DataHelper()\r\n",
        "ev = Evaluater()\r\n",
        "al = Algorithms()\r\n",
        "wr = Wrappers()\r\n",
        "st = Stats()\r\n",
        "\r\n",
        "def SuperBear(df, gridding=False):\r\n",
        "  dh = DataHelper()\r\n",
        "  '''gets the nlp results dataset ready for modeling'''\r\n",
        "  df['regularizer'] = df['regularizer'].fillna('None')\r\n",
        "  df['stacking'] = df['stacking'].astype(int)\r\n",
        "  df['dropout'] = df['dropout'].astype(int)\r\n",
        "  df['bidirectional'] = df['bidirectional'].astype(int)\r\n",
        "  act = dh.OHE(df['activation'])\r\n",
        "  reg = dh.OHE(df['regularizer'])\r\n",
        "  opt = dh.OHE(df['optimizer'])\r\n",
        "  method = dh.OHE(df['method'])\r\n",
        "  df = df.drop(['activation', 'regularizer', 'optimizer', 'method'], axis='columns')\r\n",
        "  df = pd.concat([df, act, reg, opt, method], axis='columns')\r\n",
        "  if gridding == True:\r\n",
        "    return df\r\n",
        "  df['val_loss'] = df['val_loss'].fillna(max(df['val_loss']))\r\n",
        "  df['loss'] = df['loss'].fillna(max(df['loss']))\r\n",
        "  kpi_list = ['accuracy', 'loss', 'val_accuracy', 'val_loss']\r\n",
        "  kpi = df[kpi_list]\r\n",
        "  scores = []\r\n",
        "  for i in range(len(df)):\r\n",
        "    ts = (1 - (kpi['loss'][i] / max(kpi['loss'])) + kpi['accuracy'][i])/2\r\n",
        "    vs = (1 - (kpi['val_loss'][i] / max(kpi['val_loss'])) + kpi['val_accuracy'][i])/2\r\n",
        "    score = (ts+vs) - abs(ts-vs)\r\n",
        "    scores.append(score)\r\n",
        "  df2 = df.drop(kpi_list, axis='columns')\r\n",
        "  df2['quality'] = scores\r\n",
        "  return df2\r\n",
        "\r\n",
        "def BunnyPinkears(params, len_dataset, n_features, dominant_class):\r\n",
        "  '''puts all possible gridsearch combinations in a dataframe'''\r\n",
        "  n = list(params.keys())\r\n",
        "  lst1 = []\r\n",
        "  lst2 = []\r\n",
        "  lst3 = []\r\n",
        "  lst4 = []\r\n",
        "  lst5 = []\r\n",
        "  lst6 = []\r\n",
        "  lst7 = []\r\n",
        "  lst8 = []\r\n",
        "  lst9 = []\r\n",
        "  lst10 = []\r\n",
        "  lst11 = []\r\n",
        "  lst12 = []\r\n",
        "  for i in range(len(params[n[0]])):\r\n",
        "    var1 = params[n[0]][i]\r\n",
        "    for i in range(len(params[n[1]])):\r\n",
        "      var2 = params[n[1]][i]\r\n",
        "      for i in range(len(params[n[2]])):\r\n",
        "        var3 = params[n[2]][i]\r\n",
        "        for i in range(len(params[n[3]])):\r\n",
        "          var4 = params[n[3]][i]\r\n",
        "          for i in range(len(params[n[4]])):\r\n",
        "            var5 = params[n[4]][i]\r\n",
        "            for i in range(len(params[n[5]])):\r\n",
        "              var6 = params[n[5]][i]\r\n",
        "              for i in range(len(params[n[6]])):\r\n",
        "                var7 = params[n[6]][i]\r\n",
        "                for i in range(len(params[n[7]])):\r\n",
        "                  var8 = params[n[7]][i]\r\n",
        "                  for i in range(len(params[n[8]])):\r\n",
        "                    var9 = params[n[8]][i]\r\n",
        "                    for i in range(len(params[n[9]])):\r\n",
        "                      var10 = params[n[9]][i]\r\n",
        "                      for i in range(len(params[n[10]])):\r\n",
        "                        var11 = params[n[10]][i]\r\n",
        "                        for i in range(len(params[n[11]])):\r\n",
        "                          var12 = params[n[11]][i]\r\n",
        "                          lst1.append(var1)\r\n",
        "                          lst2.append(var2)\r\n",
        "                          lst3.append(var3)\r\n",
        "                          lst4.append(var4)\r\n",
        "                          lst5.append(var5)\r\n",
        "                          lst6.append(var6)\r\n",
        "                          lst7.append(var7)\r\n",
        "                          lst8.append(var8)\r\n",
        "                          lst9.append(var9)\r\n",
        "                          lst10.append(var10)\r\n",
        "                          lst11.append(var11)\r\n",
        "                          lst12.append(var12)\r\n",
        "  df = pd.DataFrame(lst1)\r\n",
        "  df.columns = [n[0]]\r\n",
        "  df[n[1]] = lst2\r\n",
        "  df[n[2]] = lst3\r\n",
        "  df[n[3]] = lst4\r\n",
        "  df[n[4]] = lst5\r\n",
        "  df[n[5]] = lst6\r\n",
        "  df[n[6]] = lst7\r\n",
        "  df[n[7]] = lst8\r\n",
        "  df[n[8]] = lst9\r\n",
        "  df[n[9]] = lst10\r\n",
        "  df[n[10]] = lst11\r\n",
        "  df[n[11]] = lst12\r\n",
        "  df['len_dataset'] = [len_dataset] * len(df)\r\n",
        "  df['n_features'] = [n_features] * len(df)\r\n",
        "  df['dominant_class'] = [dominant_class] * len(df)\r\n",
        "  return df\r\n",
        "\r\n",
        "  def ModelBuilder(df, task, deep_learning=False):\r\n",
        "  if task == 'NLP':\r\n",
        "    df2 = SuperBear(df)\r\n",
        "  vanilla, grid, X, Xval, y, yval = wr.Vanilla(df2, 'quality', 'regression')\r\n",
        "  Xs = dh.ScaleData('standard', X)\r\n",
        "  if deep_learning == True:\r\n",
        "    model = \r\n",
        "  model = ml.Optimize(vanilla, grid, Xs, y)\r\n",
        "  return model\r\n",
        "\r\n",
        "def BuildNLP(model, grid, len_dataset=0, n_features=0, dominant_class=0.5, vocab_dim=0): #X, y, Xval, yval\r\n",
        "  combos = SuperBear(BunnyPinkears(grid, len_dataset, n_features, dominant_class), gridding=True)\r\n",
        "  c2 = dh.ScaleData('standard', combos)\r\n",
        "  combos['quality'] = model.predict(c2)\r\n",
        "  best = combos.loc[combos['quality'] == max(combos['quality'])].iloc[0]\r\n",
        "  res = dict(best)\r\n",
        "  if res['relu'] == 1:\r\n",
        "    activation = 'relu'\r\n",
        "  if res['tanh'] == 1:\r\n",
        "    activation = 'tanh'\r\n",
        "  if res['L1'] == 1:\r\n",
        "    regularizer = 'L1' \r\n",
        "  if res['L2'] == 1:\r\n",
        "    regularizer = 'L2' \r\n",
        "  if res['None'] == 1:\r\n",
        "    regularizer = 'None' \r\n",
        "  if res['adam'] == 1:\r\n",
        "    optimizer = 'adam'\r\n",
        "  if res['rmsprop'] == 1:\r\n",
        "    optimizer = 'rmsprop'\r\n",
        "  if res['sgd'] == 1:\r\n",
        "    optimizer = 'sgd'\r\n",
        "  if res['GRU'] == 1:\r\n",
        "    method = 'GRU'\r\n",
        "  if res['LSTM'] == 1:\r\n",
        "    method = 'LSTM' \r\n",
        "  dm = dl.RNN(int(res['output_dim']), int(res['embedding']), int(res['nodes']), activation, regularizer, \r\n",
        "              bool(res['stacking']), bool(res['dropout']), optimizer, method, bool(res['bidirectional']))\r\n",
        "  epochs = int(res['epochs'])\r\n",
        "  bs = int(res['batch_size'])\r\n",
        "  #dm.fit(X, y, epochs=epochs, batch_size=batch_size)\r\n",
        "  # return dm\r\n",
        "  return dm, epochs, bs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "298ew3nYB7sw"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/spe301/AI-generated-AI/main/Data/NLP8.csv').drop(['Unnamed: 0'], axis='columns')\r\n",
        "#train, val = dh.HoldOut(df)\r\n",
        "\r\n",
        "grid = {'output_dim': [2], #because we have 2 classes\r\n",
        "          'embedding': [45589], #vocab is number of unique words in dataset\r\n",
        "          'nodes': list(range(32, 68, 4)), #we will test between 32 and 64 nodes for the first layer\r\n",
        "          'activation': ['tanh', 'relu'], #we will test between relu and tanh for activation function\r\n",
        "          'regularizer': ['L1', None, 'L2'], #we will use L1 reqularization to prevent overfitting\r\n",
        "          'stacking': [False, True], #stacking makes the first 2 layers the same, we will not do this\r\n",
        "          'dropout': [False, True], #we will not use dropout because we are already using L1 regularization\r\n",
        "          'optimizer': ['adam', 'rmsprop', 'sgd'], #we will test between adam and rmsprop for optimization function\r\n",
        "          'method': ['LSTM', 'GRU'], #we will test between using an LSTM cell and a GRU cell\r\n",
        "          'bidirectional': [True, False], 'epochs': list(range(5, 60, 5)), 'batch_size': [32, 64]}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IRW16mhQcUy",
        "outputId": "06dde19c-4ae4-4b41-c48c-a0ee879df989"
      },
      "source": [
        "reg = ModelBuilder(df, 'NLP')\r\n",
        "reg"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    1.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=8,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1FsOTjsO_1K",
        "outputId": "4e9ba134-858b-4712-8b7e-5512cd4962c0"
      },
      "source": [
        "BuildNLP(reg, grid, len_dataset=360, n_features=1724, vocab_dim=45589)[0].summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          1458848   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                16640     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 1,476,562\n",
            "Trainable params: 1,476,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}